# CircleCI Custom Metrics for Datadog

This project processes CircleCI workflow data from BigQuery and sends it to Datadog as custom metrics for monitoring and analysis.

## Project Structure

```
src/
  â”œâ”€â”€ types/                    # Type definitions
  â”‚   â”œâ”€â”€ bigquery.ts          # BigQuery data types
  â”‚   â””â”€â”€ datadog.ts           # Datadog types
  â”œâ”€â”€ services/
  â”‚   â””â”€â”€ DatadogService.ts    # Datadog API integration
  â”œâ”€â”€ utils/
  â”‚   â””â”€â”€ transformers.ts      # Data transformation utilities
  â””â”€â”€ index.ts                 # Main application entry
```

## Implementation Details

### 1. Types (src/types/)

#### BigQuery Types
- Define interfaces for workflow data structure:
  - minutes (duration)
  - created_at (timestamp)
  - branch
  - workflow_name
  - status
  - project_slug
  - workflow_id

#### Datadog Types
- Define interfaces for metric submission:
  - Metric name: "ci.workflow.duration"
  - Type: gauge
  - Unit: minutes
  - Tags structure

### 2. DatadogService (src/services/)

Core service for interacting with Datadog API:
- Initialize client with API key
- Submit metrics with error handling
- Configure metric type and unit
- Handle batch processing if needed

### 3. Data Transformers (src/utils/)

Transform BigQuery data to Datadog format with special tag processing rules:

#### Data Validation
- Skip any records where any key-value pairs are null (except for the branch field which has special handling)

#### Tag Rules
- Environment tag:
  * Always include "env:ci"

- Branch tag:
  * null â†’ "branch:null"
  * master/staging/uat â†’ use as-is
  * others â†’ "branch:feature"

- Project and Workflow tags:
  * project_slug â†’ as-is
  * workflow_name â†’ as-is

- Status tag:
  * Only process success/failure statuses
  * Skip other statuses

### 4. Main Application (src/index.ts)

Entry point functionality:
- Load environment configuration
- Read BigQuery JSON data
- Transform data using utility functions
- Submit metrics to Datadog
- Handle errors and provide logging

## Environment Configuration

Required environment variables:
- DD_SITE="datadoghq.com"
- DD_API_KEY="<your-api-key>"

## Datadog Metric Format

```json
{
  "series": [{
    "metric": "ci.workflow.duration",
    "type": 3,
    "points": [{
      "timestamp": <unix_timestamp>,
      "value": <duration_in_minutes>
    }],
    "unit": "minutes",
    "tags": [
      "env:ci",
      "project_slug:<value>",
      "branch:<value>",
      "workflow:<value>",
      "status:<value>"
    ]
  }]
}
```

## Development

```bash
# Install dependencies
npm install

# Run in development mode
npm run start:dev

# Run in dry run mode (development)
npm run start:dev:dry

# Build
npm run build

# Run built version
npm start

# Run built version in dry run mode
npm run start:dry

# Run tests
npm test              # Run tests once
npm run test:watch    # Run tests in watch mode
npm run test:coverage # Run tests with coverage report
```

## Dry Run Mode

The service supports a dry run mode that logs what would be sent to Datadog without making actual API calls. This is useful for testing and verification.

When running in dry run mode:
- No metrics are sent to Datadog
- All metric details are logged to timestamped files in the `log/` directory
- Log files follow the format: `log/YYYY-MM-DDTHH-mm-ss-sssZ.log`
- Each log file contains the full metric payload, including tags and values
- The log directory is git-ignored to prevent committing log files

Example log file content:
```
=== Metric Submission Details ===
ðŸ”§ DRY RUN - No actual API call will be made

Metric: ci.workflow.duration
Type: 3
Unit: minutes

Timestamp: 1706054675 (2024-01-23T21:37:55.000Z)
Value: 15.5 minutes

Tags:
  env:ci
  project_slug:gh/HnryNZ/hnry-rails
  branch:master
  workflow:build_test_deploy
  status:success

Endpoint: /api/v2/series
==============================
```

## Testing

The project includes comprehensive test coverage:

### Transformer Tests
- Validation of branch name processing rules
- Handling of null values
- Status filtering (success/failure)
- Tag formatting
- Multiple record processing
- Timestamp and duration parsing

### Datadog Service Tests
- API integration testing with mocked responses
- Error handling scenarios
- Environment configuration validation

## Implementation Details

### Data Processing
- Processes all JSON files in the data/ directory
- Skips records with null values (except branch field)
- Transforms branch names:
  * master/staging/uat â†’ kept as-is
  * null â†’ "branch:null"
  * others â†’ "branch:feature"
- Only processes success/failure statuses
- Parses and validates timestamps and durations
- Validates required tags:
  * All metrics must include these tags:
    - env:ci
    - project_slug:<value>
    - branch:<value>
    - workflow:<value>
    - status:<value>
  * Records missing any required tags are skipped

### Datadog Integration
- Submits metrics as gauge type
- Includes required tags:
  * env:ci (always included)
  * project_slug
  * branch
  * workflow
  * status
- Handles API errors with proper logging
- Supports batch processing of multiple records

## Notes

- Metrics are submitted as gauge type
- Historical metrics ingestion must be enabled in Datadog
- Billing is based on cardinality (metric name + tag permutations)
- Only explicitly successful/failed workflow data is processed initially
- Records with null values in any fields (except branch) are skipped

## Error Handling

- Validates environment variables
- Skips invalid records without failing the entire process
- Proper error logging for API failures
- Type-safe implementation with TypeScript
